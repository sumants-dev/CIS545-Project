{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/sumants-dev/CIS545-Project/blob/main/Seasonal_weather_data__analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "acEem-kao997"
   },
   "source": [
    "# CIS 545 - Weather Big Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q07cG6yrqD7C"
   },
   "source": [
    "# 0 Introduction\n",
    "\n",
    "* Team members:  Ashley Chang, Dana Yang, Sumant Shringari"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x4cCldT5qrFq"
   },
   "source": [
    "**Our thesis: **\n",
    "\n",
    "> Predict weather with different indicators of air pollution\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ggFShNxQrEQg"
   },
   "source": [
    "**Our approach**\n",
    "\n",
    "For this set of data we experimented with three different models to evulate the best result. \n",
    "1.  Naive Bayes classification with random forest \n",
    "2.  Time series with Arima \n",
    "3.  Times series with Sarima "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_9tZyWsp4bOk"
   },
   "source": [
    "**Our data set consist of:** \n",
    "\n",
    "  Air pollution at city level \n",
    "\n",
    "    * Date range: 2020 - 2021\n",
    "    * Final data set is \n",
    "  Air pollution By Country\n",
    "\n",
    "    * Date range: 2010 - 2017\n",
    "    * Final dataset is 1352 records\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wUOIQ8U_qwQl"
   },
   "source": [
    "**Overview of results **\n",
    "\n",
    "\n",
    "> Indented block\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vpsB3j1uXUaC"
   },
   "source": [
    "#1 Data setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O74HLKAPF8-O"
   },
   "source": [
    "### 1.0 Importing data and library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "j2jqLTNq39r0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandasql in /Users/ashleyfchang/opt/anaconda3/envs/cis545/lib/python3.7/site-packages (0.7.3)\n",
      "Requirement already satisfied: sqlalchemy in /Users/ashleyfchang/opt/anaconda3/envs/cis545/lib/python3.7/site-packages (from pandasql) (1.4.28)\n",
      "Requirement already satisfied: pandas in /Users/ashleyfchang/opt/anaconda3/envs/cis545/lib/python3.7/site-packages (from pandasql) (1.3.4)\n",
      "Requirement already satisfied: numpy in /Users/ashleyfchang/opt/anaconda3/envs/cis545/lib/python3.7/site-packages (from pandasql) (1.21.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /Users/ashleyfchang/opt/anaconda3/envs/cis545/lib/python3.7/site-packages (from pandas->pandasql) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /Users/ashleyfchang/opt/anaconda3/envs/cis545/lib/python3.7/site-packages (from pandas->pandasql) (2021.3)\n",
      "Requirement already satisfied: six>=1.5 in /Users/ashleyfchang/opt/anaconda3/envs/cis545/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas->pandasql) (1.16.0)\n",
      "Requirement already satisfied: importlib-metadata in /Users/ashleyfchang/opt/anaconda3/envs/cis545/lib/python3.7/site-packages (from sqlalchemy->pandasql) (4.8.2)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /Users/ashleyfchang/opt/anaconda3/envs/cis545/lib/python3.7/site-packages (from sqlalchemy->pandasql) (1.1.2)\n",
      "Requirement already satisfied: zipp>=0.5 in /Users/ashleyfchang/opt/anaconda3/envs/cis545/lib/python3.7/site-packages (from importlib-metadata->sqlalchemy->pandasql) (3.6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in /Users/ashleyfchang/opt/anaconda3/envs/cis545/lib/python3.7/site-packages (from importlib-metadata->sqlalchemy->pandasql) (4.0.1)\n",
      "Requirement already satisfied: pandas in /Users/ashleyfchang/opt/anaconda3/envs/cis545/lib/python3.7/site-packages (1.3.4)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /Users/ashleyfchang/opt/anaconda3/envs/cis545/lib/python3.7/site-packages (from pandas) (1.21.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /Users/ashleyfchang/opt/anaconda3/envs/cis545/lib/python3.7/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /Users/ashleyfchang/opt/anaconda3/envs/cis545/lib/python3.7/site-packages (from pandas) (2021.3)\n",
      "Requirement already satisfied: six>=1.5 in /Users/ashleyfchang/opt/anaconda3/envs/cis545/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas) (1.16.0)\n",
      "Requirement already satisfied: requests in /Users/ashleyfchang/opt/anaconda3/envs/cis545/lib/python3.7/site-packages (2.26.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/ashleyfchang/opt/anaconda3/envs/cis545/lib/python3.7/site-packages (from requests) (1.26.7)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /Users/ashleyfchang/opt/anaconda3/envs/cis545/lib/python3.7/site-packages (from requests) (2.0.9)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/ashleyfchang/opt/anaconda3/envs/cis545/lib/python3.7/site-packages (from requests) (3.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/ashleyfchang/opt/anaconda3/envs/cis545/lib/python3.7/site-packages (from requests) (2021.10.8)\n",
      "Requirement already satisfied: lxml in /Users/ashleyfchang/opt/anaconda3/envs/cis545/lib/python3.7/site-packages (4.6.4)\n",
      "Requirement already satisfied: nltk in /Users/ashleyfchang/opt/anaconda3/envs/cis545/lib/python3.7/site-packages (3.6.5)\n",
      "Requirement already satisfied: tqdm in /Users/ashleyfchang/opt/anaconda3/envs/cis545/lib/python3.7/site-packages (from nltk) (4.62.3)\n",
      "Requirement already satisfied: click in /Users/ashleyfchang/opt/anaconda3/envs/cis545/lib/python3.7/site-packages (from nltk) (8.0.3)\n",
      "Requirement already satisfied: joblib in /Users/ashleyfchang/opt/anaconda3/envs/cis545/lib/python3.7/site-packages (from nltk) (1.1.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Users/ashleyfchang/opt/anaconda3/envs/cis545/lib/python3.7/site-packages (from nltk) (2021.11.10)\n",
      "Requirement already satisfied: importlib-metadata in /Users/ashleyfchang/opt/anaconda3/envs/cis545/lib/python3.7/site-packages (from click->nltk) (4.8.2)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in /Users/ashleyfchang/opt/anaconda3/envs/cis545/lib/python3.7/site-packages (from importlib-metadata->click->nltk) (4.0.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /Users/ashleyfchang/opt/anaconda3/envs/cis545/lib/python3.7/site-packages (from importlib-metadata->click->nltk) (3.6.0)\n",
      "Requirement already satisfied: pandasql in /Users/ashleyfchang/opt/anaconda3/envs/cis545/lib/python3.7/site-packages (0.7.3)\n",
      "Requirement already satisfied: pandas in /Users/ashleyfchang/opt/anaconda3/envs/cis545/lib/python3.7/site-packages (from pandasql) (1.3.4)\n",
      "Requirement already satisfied: sqlalchemy in /Users/ashleyfchang/opt/anaconda3/envs/cis545/lib/python3.7/site-packages (from pandasql) (1.4.28)\n",
      "Requirement already satisfied: numpy in /Users/ashleyfchang/opt/anaconda3/envs/cis545/lib/python3.7/site-packages (from pandasql) (1.21.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /Users/ashleyfchang/opt/anaconda3/envs/cis545/lib/python3.7/site-packages (from pandas->pandasql) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /Users/ashleyfchang/opt/anaconda3/envs/cis545/lib/python3.7/site-packages (from pandas->pandasql) (2021.3)\n",
      "Requirement already satisfied: six>=1.5 in /Users/ashleyfchang/opt/anaconda3/envs/cis545/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas->pandasql) (1.16.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /Users/ashleyfchang/opt/anaconda3/envs/cis545/lib/python3.7/site-packages (from sqlalchemy->pandasql) (1.1.2)\n",
      "Requirement already satisfied: importlib-metadata in /Users/ashleyfchang/opt/anaconda3/envs/cis545/lib/python3.7/site-packages (from sqlalchemy->pandasql) (4.8.2)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in /Users/ashleyfchang/opt/anaconda3/envs/cis545/lib/python3.7/site-packages (from importlib-metadata->sqlalchemy->pandasql) (4.0.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /Users/ashleyfchang/opt/anaconda3/envs/cis545/lib/python3.7/site-packages (from importlib-metadata->sqlalchemy->pandasql) (3.6.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandasql\n",
    "!pip install pandas\n",
    "!pip install requests\n",
    "!pip install lxml\n",
    "!pip install nltk\n",
    "!pip install pandasql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "Tr7ssJ-rsSBC"
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import pandasql as psql\n",
    "from lxml import html\n",
    "import requests\n",
    "import nltk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in /Users/ashleyfchang/opt/anaconda3/envs/cis545/lib/python3.7/site-packages (3.5.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /Users/ashleyfchang/opt/anaconda3/envs/cis545/lib/python3.7/site-packages (from matplotlib) (8.4.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/ashleyfchang/opt/anaconda3/envs/cis545/lib/python3.7/site-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/ashleyfchang/opt/anaconda3/envs/cis545/lib/python3.7/site-packages (from matplotlib) (1.21.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/ashleyfchang/opt/anaconda3/envs/cis545/lib/python3.7/site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/ashleyfchang/opt/anaconda3/envs/cis545/lib/python3.7/site-packages (from matplotlib) (21.3)\n",
      "Requirement already satisfied: setuptools-scm>=4 in /Users/ashleyfchang/opt/anaconda3/envs/cis545/lib/python3.7/site-packages (from matplotlib) (6.3.2)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/ashleyfchang/opt/anaconda3/envs/cis545/lib/python3.7/site-packages (from matplotlib) (4.28.3)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /Users/ashleyfchang/opt/anaconda3/envs/cis545/lib/python3.7/site-packages (from matplotlib) (3.0.6)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/ashleyfchang/opt/anaconda3/envs/cis545/lib/python3.7/site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: six>=1.5 in /Users/ashleyfchang/opt/anaconda3/envs/cis545/lib/python3.7/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Requirement already satisfied: tomli>=1.0.0 in /Users/ashleyfchang/opt/anaconda3/envs/cis545/lib/python3.7/site-packages (from setuptools-scm>=4->matplotlib) (1.2.2)\n",
      "Requirement already satisfied: setuptools in /Users/ashleyfchang/opt/anaconda3/envs/cis545/lib/python3.7/site-packages (from setuptools-scm>=4->matplotlib) (58.0.4)\n",
      "Requirement already satisfied: seaborn in /Users/ashleyfchang/opt/anaconda3/envs/cis545/lib/python3.7/site-packages (0.11.2)\n",
      "Requirement already satisfied: pandas>=0.23 in /Users/ashleyfchang/opt/anaconda3/envs/cis545/lib/python3.7/site-packages (from seaborn) (1.3.4)\n",
      "Requirement already satisfied: matplotlib>=2.2 in /Users/ashleyfchang/opt/anaconda3/envs/cis545/lib/python3.7/site-packages (from seaborn) (3.5.0)\n",
      "Requirement already satisfied: numpy>=1.15 in /Users/ashleyfchang/opt/anaconda3/envs/cis545/lib/python3.7/site-packages (from seaborn) (1.21.4)\n",
      "Requirement already satisfied: scipy>=1.0 in /Users/ashleyfchang/opt/anaconda3/envs/cis545/lib/python3.7/site-packages (from seaborn) (1.7.3)\n",
      "Requirement already satisfied: setuptools-scm>=4 in /Users/ashleyfchang/opt/anaconda3/envs/cis545/lib/python3.7/site-packages (from matplotlib>=2.2->seaborn) (6.3.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/ashleyfchang/opt/anaconda3/envs/cis545/lib/python3.7/site-packages (from matplotlib>=2.2->seaborn) (2.8.2)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /Users/ashleyfchang/opt/anaconda3/envs/cis545/lib/python3.7/site-packages (from matplotlib>=2.2->seaborn) (3.0.6)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/ashleyfchang/opt/anaconda3/envs/cis545/lib/python3.7/site-packages (from matplotlib>=2.2->seaborn) (0.11.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/ashleyfchang/opt/anaconda3/envs/cis545/lib/python3.7/site-packages (from matplotlib>=2.2->seaborn) (21.3)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /Users/ashleyfchang/opt/anaconda3/envs/cis545/lib/python3.7/site-packages (from matplotlib>=2.2->seaborn) (8.4.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/ashleyfchang/opt/anaconda3/envs/cis545/lib/python3.7/site-packages (from matplotlib>=2.2->seaborn) (1.3.2)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/ashleyfchang/opt/anaconda3/envs/cis545/lib/python3.7/site-packages (from matplotlib>=2.2->seaborn) (4.28.3)\n",
      "Requirement already satisfied: pytz>=2017.3 in /Users/ashleyfchang/opt/anaconda3/envs/cis545/lib/python3.7/site-packages (from pandas>=0.23->seaborn) (2021.3)\n",
      "Requirement already satisfied: six>=1.5 in /Users/ashleyfchang/opt/anaconda3/envs/cis545/lib/python3.7/site-packages (from python-dateutil>=2.7->matplotlib>=2.2->seaborn) (1.16.0)\n",
      "Requirement already satisfied: setuptools in /Users/ashleyfchang/opt/anaconda3/envs/cis545/lib/python3.7/site-packages (from setuptools-scm>=4->matplotlib>=2.2->seaborn) (58.0.4)\n",
      "Requirement already satisfied: tomli>=1.0.0 in /Users/ashleyfchang/opt/anaconda3/envs/cis545/lib/python3.7/site-packages (from setuptools-scm>=4->matplotlib>=2.2->seaborn) (1.2.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install matplotlib\n",
    "!pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "5IU933x_TJ1m"
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import json\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "import glob\n",
    "import seaborn as sns\n",
    "import re\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "sNGOaWR3Img1",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "air_polution_pd = pd.read_csv(\"./Data/raw/PM2.5 Global Air Pollution 2010-2017.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5RTwD5R5lFvg"
   },
   "source": [
    "Importing 2021 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "6AlBb1cmpu_8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ashleyfchang/opt/anaconda3/envs/cis545/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3457: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version.\n",
      "\n",
      "\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "acqin_data_pd21 = pd.read_csv(\"./Data/raw/waqi-covid19-airqualitydata-2020.csv\", error_bad_lines=False, header = 0, skiprows=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jIjkxw00k880"
   },
   "source": [
    "Importing 2020 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "uh9bUAM2yNID"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './Data/raw/waqi-covid19-airqualitydata-2020Q2.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/1l/w4y7yw0d3696kyv235sfd3hw0000gn/T/ipykernel_22374/1146192889.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0macqin_data_pd20_Q1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./Data/raw/waqi-covid19-airqualitydata-2020Q1.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror_bad_lines\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskiprows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0macqin_data_pd20_Q2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./Data/raw/waqi-covid19-airqualitydata-2020Q2.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror_bad_lines\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskiprows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0macqin_data_pd20_Q3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./Data/raw/Data/waqi-covid19-airqualitydata-2020Q3.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror_bad_lines\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskiprows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0macqin_data_pd20_Q4\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./Data/raw/waqi-covid19-airqualitydata-2020Q4.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror_bad_lines\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskiprows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/cis545/lib/python3.7/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/cis545/lib/python3.7/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/cis545/lib/python3.7/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/cis545/lib/python3.7/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 811\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/cis545/lib/python3.7/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1038\u001b[0m             )\n\u001b[1;32m   1039\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1040\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/cis545/lib/python3.7/site-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/cis545/lib/python3.7/site-packages/pandas/io/parsers/base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m    227\u001b[0m             \u001b[0mmemory_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"memory_map\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m             \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"storage_options\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m             \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"encoding_errors\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"strict\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m         )\n\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/cis545/lib/python3.7/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    705\u001b[0m                 \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    706\u001b[0m                 \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 707\u001b[0;31m                 \u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    708\u001b[0m             )\n\u001b[1;32m    709\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './Data/raw/waqi-covid19-airqualitydata-2020Q2.csv'"
     ]
    }
   ],
   "source": [
    "acqin_data_pd20_Q1 = pd.read_csv(\"./Data/raw/waqi-covid19-airqualitydata-2020Q1.csv\", error_bad_lines=False, header = 0, skiprows=4)\n",
    "acqin_data_pd20_Q2 = pd.read_csv(\"./Data/raw/waqi-covid19-airqualitydata-2020Q2.csv\", error_bad_lines=False, header = 0, skiprows=4)\n",
    "acqin_data_pd20_Q3 = pd.read_csv(\"./Data/raw/Data/waqi-covid19-airqualitydata-2020Q3.csv\", error_bad_lines=False, header = 0, skiprows=4)\n",
    "acqin_data_pd20_Q4 = pd.read_csv(\"./Data/raw/waqi-covid19-airqualitydata-2020Q4.csv\", error_bad_lines=False, header = 0, skiprows=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sjmAh3iXlLTC"
   },
   "source": [
    "Importing 2019 data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0VpWXraplK8t"
   },
   "outputs": [],
   "source": [
    "acqin_data_pd19_Q1 = pd.read_csv(\"./Data/raw/Data/waqi-covid19-airqualitydata-2019Q1.csv\", error_bad_lines=False, header = 0, skiprows=4)\n",
    "acqin_data_pd19_Q2 = pd.read_csv(\"./Data/raw/Data/waqi-covid19-airqualitydata-2019Q2.csv\", error_bad_lines=False, header = 0, skiprows=4)\n",
    "acqin_data_pd19_Q3 = pd.read_csv(\"./Data/raw/Data/waqi-covid19-airqualitydata-2019Q3.csv\", error_bad_lines=False, header = 0, skiprows=4)\n",
    "acqin_data_pd19_Q4 = pd.read_csv(\"./Data/raw/aqi-covid19-airqualitydata-2019Q4.csv\", error_bad_lines=False, header = 0, skiprows=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qwlLT-kD12q3"
   },
   "outputs": [],
   "source": [
    "population = pd.read_csv(\"./Data/raw/Data//city_population.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7REU4nXlF4OG"
   },
   "source": [
    "## 1.2 ACQIN air polution dataset data cleaning and wrangling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8jYjLRpyU0UD"
   },
   "source": [
    "Data sourced from \n",
    "*  Polluation and tempature data from AQICN : https://aqicn.org/data-platform/covid19/verify/821c0eaf-e7cd-41e7-a6e3-84b8dfea1988\n",
    "      * Raw data:\n",
    "            *  Time line: 2019 - 2021 \n",
    "            *  # of records : 613,561 after transpose\n",
    "            *  # of attributes: 21\n",
    "* Population data from world population :  https://worldpopulationreview.com/world-cities\n",
    "      * Raw data:\n",
    "            *  Time line: 2020 - 2021 \n",
    "            *  # of records : 1170\n",
    "            *  # of attributes: 3\n",
    "Overall goals of data cleaning includes: \n",
    "\n",
    "\n",
    "*  Combine datasets between each quaters and year for the acqin dataset\n",
    "*  Drop any observeration that had 0 count in data collected for the sample \n",
    "*  Normalize the population dataset and join it into the ACQIN dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BFNij9cAvLWr"
   },
   "source": [
    "### 1.1.1 Data overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dlLpLkFzrpqw"
   },
   "source": [
    "Let's first take a quick look at the format of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "sfB7KEkF0Tz_",
    "outputId": "d573e1e1-39a3-46c9-d246-40d436e94e08"
   },
   "outputs": [],
   "source": [
    "acqin_data_pd20_Q1.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2K0P1jmivTer"
   },
   "source": [
    "A quick look at our data set and the features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MwhwRayV0lIv",
    "outputId": "0f01a69b-3cfd-417b-b8d6-ba355d0118b1"
   },
   "outputs": [],
   "source": [
    "num_country = psql.sqldf(\"SELECT COUNT(DISTINCT Country) AS num_country FROM acqin_data_pd20_Q1\")\n",
    "num_city = psql.sqldf(\"SELECT COUNT(DISTINCT city) AS num_city FROM acqin_data_pd20_Q1\")\n",
    "features = psql.sqldf(\"SELECT DISTINCT Specie AS features FROM acqin_data_pd20_Q1\")\n",
    "print(num_city)\n",
    "print(num_country)\n",
    "print(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gFhV2oJjXJSS"
   },
   "source": [
    "### 1.1.2 Data cleaning and joining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "et7ZS0P1KE4x"
   },
   "source": [
    "Lets join the four quarters of 2020 with 2021 of dataset together \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "peqU3de0KEWD"
   },
   "outputs": [],
   "source": [
    "\n",
    "frames = [acqin_data_pd20_Q1, acqin_data_pd20_Q2,acqin_data_pd20_Q3,acqin_data_pd20_Q4, acqin_data_pd21, acqin_data_pd19_Q1, acqin_data_pd19_Q2,acqin_data_pd19_Q3,acqin_data_pd19_Q4]\n",
    "acqin_all_pollution_df = pd.concat(frames)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "go0KDa-aiCvM"
   },
   "source": [
    "Drop where the count is 0; drop records where there are no samples collected meaning the count is 0. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M4Sr3HkeiRix"
   },
   "outputs": [],
   "source": [
    "acqin_all_pollution_valid_values = acqin_all_pollution_df[(acqin_all_pollution_df[['count']] != 0).all(axis =1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZPLwYSH4MGzh",
    "outputId": "67f39c04-378e-464c-94a8-f71e029b7237"
   },
   "outputs": [],
   "source": [
    "print(acqin_all_pollution_valid_values.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XilBOrkuX1np"
   },
   "source": [
    "Next, lets transpose the dataset so we have the features as columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ew3JPvCXf83T"
   },
   "outputs": [],
   "source": [
    "acqin_all_pollution_df_transposed = acqin_all_pollution_valid_values.pivot_table(index= ['Date','Country', 'City'], columns='Specie', values='median', fill_value=0).rename_axis(None, axis=1).reset_index()\n",
    "acqin_all_pollution_df_transposed['Date'] = acqin_all_pollution_df_transposed['Date'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 626
    },
    "id": "oG8aqXRhd7yb",
    "outputId": "3af6b847-de3a-4828-9d77-9d1b35e845c9"
   },
   "outputs": [],
   "source": [
    "acqin_all_pollution_df_transposed = acqin_all_pollution_df_transposed.sort_values(by=['City', 'Date'])\n",
    "acqin_all_pollution_df_transposed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 626
    },
    "id": "ZDgdFKlx_QP9",
    "outputId": "106b8b55-9ee7-45f3-9e99-9c46c5116a52"
   },
   "outputs": [],
   "source": [
    "query = '''\n",
    "SELECT *\n",
    "FROM acqin_all_pollution_df_transposed\n",
    "WHERE  dew != 0.0 AND pressure != 0.0 AND so2 != 0.0  AND pm25 != 0.0\n",
    "AND temperature != 0.0\n",
    "'''\n",
    "\n",
    "vaild_values_pollution = psql.sqldf(query)\n",
    "\n",
    "vaild_values_pollution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PyAUAHGIAUG7",
    "outputId": "fe6c2526-e7a2-49c5-adb7-20b1ce0b23e0"
   },
   "outputs": [],
   "source": [
    "print(vaild_values_pollution.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "id": "Q28ACHsxTJAP",
    "outputId": "dc0e5fe9-d464-43a4-a38a-95c24cf529d7"
   },
   "outputs": [],
   "source": [
    "query = '''\n",
    "SELECT City, Date, temperature \n",
    "FROM acqin_all_pollution_df_transposed\n",
    "WHERE temperature = 0.0\n",
    "ORDER BY City, Date \n",
    "\n",
    "'''\n",
    "\n",
    "temp_data = psql.sqldf(query)\n",
    "temp_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4FAyoloLRhPC"
   },
   "source": [
    "Drop where tempature is 0 or NULL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MTOeIsR4RlMR"
   },
   "outputs": [],
   "source": [
    "#acqin_all_pollution_df_transposed = acqin_all_pollution_df_transposed[(acqin_all_pollution_df_transposed[['temperature']] != 0).all(axis =1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-Cm_GTzGktIk",
    "outputId": "03084607-42ba-4fcb-e132-25427522f367"
   },
   "outputs": [],
   "source": [
    "print(acqin_all_pollution_df_transposed.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pprseWxrg7z5"
   },
   "source": [
    "Let's add a two Year and month field for joining into the population data later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bChFuHo1g7SE"
   },
   "outputs": [],
   "source": [
    "acqin_all_pollution_df_transposed['short_date'] = acqin_all_pollution_df_transposed['Date'].str[:7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VJdT0N6fCn2T"
   },
   "outputs": [],
   "source": [
    "vaild_values_pollution['short_date'] = vaild_values_pollution['Date'].str[:7]\n",
    "vaild_values_pollution['month'] = vaild_values_pollution['Date'].str[5:7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vaild_values_pollution['datetime'] = pd.to_datetime(df['Date'], format = '%Y%m%d')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JPYcfjqTrkDR"
   },
   "source": [
    "Next we want to normalize the population data across the 12 months time period to match with the acqin data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6oRKG_D6jOae",
    "outputId": "9b13d529-0299-4877-d8b6-7c6b93a484ba"
   },
   "outputs": [],
   "source": [
    "print(population.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n0roFMp8p9DO"
   },
   "outputs": [],
   "source": [
    "## normailize the population acorss the 12 months in the year for each city \n",
    "query19 = \"SELECT Name, Prev -(Population - Prev)- (Population - Prev) as StartPopulation, (Population - Prev)/12  as increment FROM population \"\n",
    "query20 = \"SELECT Name, Prev -(Population - Prev) as StartPopulation, (Population - Prev)/12  as increment FROM population \"\n",
    "query21 = \"SELECT Name,  Prev  as StartPopulation, (Population - Prev)/12  as increment FROM population\"\n",
    "\n",
    "## defining the 2020 and 2021 dates\n",
    "\n",
    "m2019 = {'Date': ['2019-01', '2019-02','2019-03','2019-04', \n",
    "                  '2019-05','2019-06-01','2019-07-01', '2019-08-01',\n",
    "                  '2019-09','2019-10', '2019-11','2019-12'], 'num': [1,2,3,4,5,6,7,8,9,10,11,12]}\n",
    "m2020 = {'Date': ['2020-01', '2020-02','2020-03','2020-04', \n",
    "                  '2020-05','2020-06-01','2020-07-01', '2020-08-01',\n",
    "                  '2020-09','2020-10', '2020-11','2020-12'], 'num': [1,2,3,4,5,6,7,8,9,10,11,12]}\n",
    "m2021 = {'Date': ['2021-01', '2021-02','2021-03','2021-04', \n",
    "                  '2021-05','2021-06','2021-07', '2021-08',\n",
    "                  '2021-09','2021-10', '2021-11','2021-12'], 'num': [1,2,3,4,5,6,7,8,9,10,11,12]}\n",
    "months19 = pd.DataFrame(data = m2019, columns =['Date', 'num'])\n",
    "months20 = pd.DataFrame(data = m2020, columns =['Date', 'num'])\n",
    "months21 = pd.DataFrame(data = m2021, columns =['Date', 'num'])\n",
    "\n",
    "distributed_population19 = psql.sqldf(query19)\n",
    "distributed_population20 = psql.sqldf(query20)\n",
    "distributed_population21 = psql.sqldf(query21)\n",
    "\n",
    "#cross join the get the set of each city with each month \n",
    "query_month19 = 'SELECT * FROM months19 CROSS JOIN distributed_population19 ORDER BY Name'\n",
    "distributed_population19 = psql.sqldf(query_month19)\n",
    "\n",
    "query_month20 = 'SELECT * FROM months20 CROSS JOIN distributed_population20 ORDER BY Name'\n",
    "distributed_population20 = psql.sqldf(query_month20)\n",
    "\n",
    "query_month21 = 'SELECT * FROM months21 CROSS JOIN distributed_population21 ORDER BY Name'\n",
    "distributed_population21 = psql.sqldf(query_month21)\n",
    "\n",
    "#calculate the rolling total \n",
    "rolling_pop_query19 = '''\n",
    "SELECT Date, Name, StartPopulation + increment*num as Population, num as month \n",
    "FROM distributed_population19\n",
    "'''\n",
    "distributed_population19 = psql.sqldf(rolling_pop_query19)\n",
    "rolling_pop_query20 = '''\n",
    "SELECT Date, Name, StartPopulation + increment*num as Population, num as month \n",
    "FROM distributed_population20\n",
    "'''\n",
    "distributed_population20 = psql.sqldf(rolling_pop_query20)\n",
    "\n",
    "rolling_pop_query21 = '''\n",
    "SELECT Date, Name, StartPopulation + increment*num as Population, num as month \n",
    "FROM distributed_population21\n",
    "'''\n",
    "distributed_population21 = psql.sqldf(rolling_pop_query21)\n",
    "\n",
    "frames = [distributed_population20, distributed_population21,distributed_population19]\n",
    "distributed_population = pd.concat(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "id": "2jYZFkiteabs",
    "outputId": "163dbcbb-1a26-4da9-f778-7253c3d6d2d3"
   },
   "outputs": [],
   "source": [
    "distributed_population\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n6DRDHw6ZM7R"
   },
   "source": [
    "Let's join the population dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T88zC5-iZMBl"
   },
   "outputs": [],
   "source": [
    "query = '''\n",
    "        SELECT * \n",
    "        FROM acqin_all_pollution_df_transposed a LEFT JOIN distributed_population p \n",
    "        ON (a.CITY = p.Name ) \n",
    "        ''' \n",
    "\n",
    "  #AND a.Date LIKE CONCAT(p.Date+'%') \n",
    "  #a.CITY = p.Name AND\n",
    "\n",
    "copyOfpop = distributed_population.copy(deep = True)\n",
    "weather_with_pop = pd.merge(acqin_all_pollution_df_transposed, distributed_population,how='inner', left_on=['City', 'short_date'], right_on=['Name', 'Date'])\n",
    "\n",
    "weather_with_pop_small = pd.merge(vaild_values_pollution, copyOfpop ,how='inner', left_on=['City', 'short_date'], right_on=['Name', 'Date'])\n",
    "#weather_with_pop = psql.sqldf(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZPKwmaPVDgsm",
    "outputId": "8bc45140-9c90-4f0c-d2ab-255f43b1adc3"
   },
   "outputs": [],
   "source": [
    "print(weather_with_pop_small.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 326
    },
    "id": "rUMrgoCF2CIW",
    "outputId": "a682fbf2-b81e-4811-ba3b-7b41e4bc2cd8"
   },
   "outputs": [],
   "source": [
    "weather_with_pop.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZS8HgKs6kdk4",
    "outputId": "0483df13-d8b4-411f-a365-c389554b22dd"
   },
   "outputs": [],
   "source": [
    "print(acqin_all_pollution_df_transposed.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8bXakHt8kEYA",
    "outputId": "d464db6c-5dd1-434b-ee10-f85d17e96f8c"
   },
   "outputs": [],
   "source": [
    "print(weather_with_pop.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gqgSZv2JpJTp"
   },
   "source": [
    "## 1.1.3 drop extra columns and rename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wGCUOYftpRx7"
   },
   "outputs": [],
   "source": [
    "weather_with_pop = weather_with_pop.drop(columns=['Date_y', 'Name'])\n",
    "weather_with_pop= weather_with_pop.rename(columns={'Date_x': 'Date'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RelJWSNdDyRC"
   },
   "outputs": [],
   "source": [
    "weather_with_pop_small = weather_with_pop_small.drop(columns=['Date_y', 'Name'])\n",
    "weather_with_pop_small= weather_with_pop_small.rename(columns={'Date_x': 'Date'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 626
    },
    "id": "Gz7USASMqCmx",
    "outputId": "db72fb4b-a8c8-4c80-ade8-24860c51ea7f"
   },
   "outputs": [],
   "source": [
    "weather_with_pop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_with_pop_small['datetime'] = pd.to_datetime(df['Date'], format = '%Y%m%d')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cpkQPZREqYcp"
   },
   "source": [
    "Finally, we will export our cleanned dataframe out to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_with_pop['datetime'] = pd.to_datetime(df['Date'], format = '%Y%m%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hpvrFaupqS9o"
   },
   "outputs": [],
   "source": [
    "weather_with_pop.to_csv('/content/drive/MyDrive/MCIT/CIS545/Data/weather_with_pop.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JaU0Zhmsb253"
   },
   "source": [
    "##1.3 Country level pollution data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sfahcsU9uNZX"
   },
   "source": [
    "### 1.3.1 Extraction of standardlize country codes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OgRrLssguKvk"
   },
   "source": [
    "For each of our data set, we extract the country name to country code mapping through wikipedia. Our approach is to make a request to the wikipedia page, and then use xpath to find the list of country names and country code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QTW3fbp4uIIR"
   },
   "outputs": [],
   "source": [
    "def get_country_codes():\n",
    "    wiki = requests.get(\"https://en.wikipedia.org/wiki/ISO_3166-1_alpha-3\")\n",
    "    dom_tree = html.fromstring(wiki.content)\n",
    "    xpath = \"//div[@class=\\\"plainlist\\\"]/ul/li\"\n",
    "    country_list  = dom_tree.xpath(xpath)\n",
    "    country_map = {}\n",
    "    for country_elem in country_list:\n",
    "        country_map[country_elem[2].text] = country_elem[1].text\n",
    "    return country_map\n",
    "        \n",
    "def set_country_value(df):\n",
    "    country_to_code = get_country_codes()\n",
    "    #df[\"Country\"] = df['Country Name'].apply(lambda elem: country_to_code.get(elem))\n",
    "    df.insert(0, 'iso_code',df['Country Name'].apply(lambda elem: country_to_code.get(elem)) )\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xbSzEmx2zisG"
   },
   "outputs": [],
   "source": [
    "air_polution_pd = set_country_value(air_polution_pd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VKeSkDSjH_BG"
   },
   "source": [
    "\n",
    "Overall goals of data cleaning includes: \n",
    "\n",
    "\n",
    "*   Extract a standardlized date range and group the data by year and month \n",
    "*   Ensure consist country data format by updating country to include ISO ; https://en.wikipedia.org/wiki/List_of_ISO_3166_country_codes (3-alpha code)\n",
    "*   Drop columns that are not needed for analysis \n",
    "*   Drop any rows that have nulls \n",
    "*   Export cleaned dataset\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UCevp5-hunmE"
   },
   "source": [
    "First, we will print the initial pollution dataframe to understand the shape of the data we are working with. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "Nkczt5pMunJF",
    "outputId": "178d718b-3d21-4303-eb43-8148daa78b09"
   },
   "outputs": [],
   "source": [
    "air_polution_pd.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lruHWsMWvlIW"
   },
   "source": [
    "The next step we will use Pandas describe function to understand our dataset a bit further. \n",
    "\n",
    "\n",
    "*   The data set consist of 240 countries data in air pollution between 2010 to 2017 \n",
    "*   There are no country missing a data record between 2010 to 2017, since 2010 - 2017 all have 240 count of records \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 297
    },
    "id": "kcYSsO8wvbC2",
    "outputId": "c58de3d0-9dde-4032-b00f-68af0796afc1"
   },
   "outputs": [],
   "source": [
    "air_polution_pd.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "KDdY6FQqHxvK",
    "outputId": "597a4341-97cd-425e-cf53-e86f34bd1761"
   },
   "outputs": [],
   "source": [
    "air_polution_pd_cleaned = air_polution_pd.dropna()\n",
    "\n",
    "air_polution_pd_cleaned = air_polution_pd_cleaned.drop(columns=['Country Name', 'Country Code'])\n",
    "air_polution_pd_cleaned.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K65OqV_IKLl-"
   },
   "outputs": [],
   "source": [
    " air_polution_pd_cleaned_transposed =  air_polution_pd_cleaned.set_index('iso_code').stack().reset_index().rename(columns={'level_1': 'year', 0:'percent'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "Ktdzd289V8fC",
    "outputId": "3c720042-d74e-49e5-ee15-d645fcd63eb3"
   },
   "outputs": [],
   "source": [
    "air_polution_pd_cleaned_transposed.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U2xj5OV7xzK_"
   },
   "source": [
    "Next, we wil reformat the dataset that is consistent with the other datasets. We will have the iso_code, year and percent as columns of our dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a6xWeES05MUJ"
   },
   "source": [
    "Finally, we will export our cleanned dataframe out to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sedNJCJQzMWK"
   },
   "outputs": [],
   "source": [
    "air_polution_pd_cleaned_transposed.to_csv('/content/drive/MyDrive/MCIT/CIS545/Data/pollution_data_cleaned.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NtUeUHLombEF"
   },
   "source": [
    "# 2 Graphing trends and analyzing the data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bcDOE0jTTacV"
   },
   "source": [
    "\n",
    "\n",
    "*   Line graphs on trend: overall change with year on Y axis \n",
    "*   Histogram for top 10 countries: comparison between each country by the attribute \n",
    "*   Globe view heat map\n",
    "*   Feature correlations heatmap\n",
    "*   Trend: % change by year group by region "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vjXw7Yhjq6vB"
   },
   "source": [
    "Below are graphing functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sGQYf9VyVL-y"
   },
   "outputs": [],
   "source": [
    "def linePlot(dataset):\n",
    "  sns.set(rc = {'figure.figsize':(15,8)})\n",
    "  sns.lineplot(data=dataset, x=\"year\", y=\"percent\", hue=\"iso_code\", style=\"iso_code\")\n",
    "  plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QHnMS9-JS3Er"
   },
   "source": [
    "Annual year pollution of top 10 countries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 535
    },
    "id": "b1ZBTzi8KjyW",
    "outputId": "df9a8b72-a2f8-400a-bc08-85d9f14beb7b"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "query_a = '''\n",
    "SELECT year, percent, iso_code\n",
    "FROM air_polution_pd_cleaned_transposed\n",
    "WHERE  iso_code IN(\n",
    "  SELECT DISTINCT iso_code \n",
    "  FROM air_polution_pd_cleaned_transposed \n",
    "  ORDER BY percent DESC\n",
    "  LIMIT 20\n",
    ")\n",
    "ORDER BY year ASC, iso_code, percent\n",
    "'''\n",
    "\n",
    "graph_query0 = psql.sqldf(query_a)\n",
    "linePlot(graph_query0)\n",
    "plt.title('Countries with highest pollution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 535
    },
    "id": "ehyZIFQNTtaM",
    "outputId": "3ad067d2-2426-4d30-e85a-59b073207c00"
   },
   "outputs": [],
   "source": [
    "\n",
    "query_b = '''\n",
    "SELECT year, percent, iso_code\n",
    "FROM air_polution_pd_cleaned_transposed\n",
    "WHERE  iso_code IN(\n",
    "  SELECT DISTINCT iso_code \n",
    "  FROM air_polution_pd_cleaned_transposed \n",
    "  ORDER BY percent \n",
    "  LIMIT 20\n",
    ")\n",
    "ORDER BY year ASC, iso_code, percent\n",
    "'''\n",
    "\n",
    "graph_query0 = psql.sqldf(query_b)\n",
    "linePlot(graph_query0)\n",
    "plt.title('Countries with lowest pollution')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1dnkAoGtrL2s"
   },
   "source": [
    "Worst polluters at the city level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AZDwi44fuWBk"
   },
   "outputs": [],
   "source": [
    "def cityLevelBarPlot(data_input):\n",
    "  sns.set_theme(style=\"whitegrid\")\n",
    "  sns.set(rc = {'figure.figsize':(25,8)})\n",
    "  sns.barplot(x =\"City\", y = \"pollution\", data=data_input )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FMfg6oRcrBrr"
   },
   "outputs": [],
   "source": [
    "query1 = '''\n",
    "SELECT  City, max(pm25) as pollution\n",
    "FROM weather_with_pop\n",
    "WHERE Date LIKE '2021-01%'\n",
    "GROUP BY City\n",
    "ORDER BY pm25 DESC\n",
    "LIMIT 20\n",
    "'''\n",
    "\n",
    "query2 = '''\n",
    "SELECT City, max(pm25) as pollution\n",
    "FROM weather_with_pop\n",
    "WHERE Date LIKE '2021-11%'\n",
    "GROUP BY City\n",
    "ORDER BY pm25 DESC\n",
    "LIMIT 20\n",
    "'''\n",
    "\n",
    "\n",
    "graph_query1 = psql.sqldf(query1)\n",
    "graph_query2 = psql.sqldf(query2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9X46jink6B2K"
   },
   "outputs": [],
   "source": [
    "query3 = '''\n",
    "SELECT City, max(pm25) as pollution, short_date as date\n",
    "FROM weather_with_pop\n",
    "WHERE City IN (\n",
    "  SELECT City\n",
    "  FROM weather_with_pop\n",
    "  WHERE Date LIKE '2021-06%' \n",
    "  GROUP BY City\n",
    "  ORDER BY pm25 DESC\n",
    "  LIMIT 10\n",
    ")\n",
    "GROUP BY City, short_date\n",
    "ORDER BY short_date, pm25 DESC \n",
    "'''\n",
    "\n",
    "graph_query3 = psql.sqldf(query3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2W5aMB0g2gjK",
    "outputId": "4d8eec53-919b-4af8-9f0d-1102da85a772"
   },
   "outputs": [],
   "source": [
    "print(graph_query3.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 669
    },
    "id": "Hmuiyd1pv3pC",
    "outputId": "009fd27c-fd30-44bd-8dfa-55c805b37299"
   },
   "outputs": [],
   "source": [
    "graph_query1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 433
    },
    "id": "yEl8DF3Ov2R6",
    "outputId": "8d60a986-28c2-4053-bbb8-a7f4f12275d5"
   },
   "outputs": [],
   "source": [
    "cityLevelBarPlot(graph_query1)\n",
    "plt.title('Top pollution cities in the summer (Jun)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 433
    },
    "id": "fyP20iQFzLNN",
    "outputId": "8847b998-7d2f-47c5-ed4c-a94b9e1222ee"
   },
   "outputs": [],
   "source": [
    "cityLevelBarPlot(graph_query2)\n",
    "plt.title('Top pollution cities in the winter (Nov)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VU3tGO3s84Xb"
   },
   "source": [
    "Generally, we are seeing that there is a rise in pm 2.5 in the winter seasons between November to Feburary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 359
    },
    "id": "2qchDds22bb8",
    "outputId": "bb32b3f7-8ae0-4ebe-96b6-f486cb0dee2c"
   },
   "outputs": [],
   "source": [
    "sns.set(rc = {'figure.figsize':(30,8)})\n",
    "sns.lineplot(data=graph_query3, x=\"date\", y=\"pollution\", hue=\"City\", style=\"City\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7tzpb_porRGv"
   },
   "source": [
    "training time \n",
    "accuracy \n",
    "notablity of the approach \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mCdO4xIOMkbk"
   },
   "source": [
    "Graph relationship between pollution and tempature "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "gqKqtv3nFaZ5"
   },
   "outputs": [
    {
     "ename": "PandaSQLException",
     "evalue": "(sqlite3.OperationalError) no such table: vaild_values_pollution\n[SQL: \nSELECT AVG(temperature) as temperature , AVG(pm25) as pm25, short_date\nFROM vaild_values_pollution\nGROUP BY short_date \n]\n(Background on this error at: https://sqlalche.me/e/14/e3q8)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m~/opt/anaconda3/envs/cis545/lib/python3.7/site-packages/sqlalchemy/engine/base.py\u001b[0m in \u001b[0;36m_execute_context\u001b[0;34m(self, dialect, constructor, statement, parameters, execution_options, *args, **kw)\u001b[0m\n\u001b[1;32m   1802\u001b[0m                     self.dialect.do_execute(\n\u001b[0;32m-> 1803\u001b[0;31m                         \u001b[0mcursor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1804\u001b[0m                     )\n",
      "\u001b[0;32m~/opt/anaconda3/envs/cis545/lib/python3.7/site-packages/sqlalchemy/engine/default.py\u001b[0m in \u001b[0;36mdo_execute\u001b[0;34m(self, cursor, statement, parameters, context)\u001b[0m\n\u001b[1;32m    731\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdo_execute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcursor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 732\u001b[0;31m         \u001b[0mcursor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    733\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOperationalError\u001b[0m: no such table: vaild_values_pollution",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m~/opt/anaconda3/envs/cis545/lib/python3.7/site-packages/pandasql/sqldf.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, query, env)\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_sql\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mDatabaseError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/cis545/lib/python3.7/site-packages/pandas/io/sql.py\u001b[0m in \u001b[0;36mread_sql\u001b[0;34m(sql, con, index_col, coerce_float, params, parse_dates, columns, chunksize)\u001b[0m\n\u001b[1;32m    633\u001b[0m             \u001b[0mparse_dates\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparse_dates\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 634\u001b[0;31m             \u001b[0mchunksize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchunksize\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    635\u001b[0m         )\n",
      "\u001b[0;32m~/opt/anaconda3/envs/cis545/lib/python3.7/site-packages/pandas/io/sql.py\u001b[0m in \u001b[0;36mread_query\u001b[0;34m(self, sql, index_col, coerce_float, parse_dates, params, chunksize, dtype)\u001b[0m\n\u001b[1;32m   1578\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1579\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1580\u001b[0m         \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/cis545/lib/python3.7/site-packages/pandas/io/sql.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1423\u001b[0m         \u001b[0;34m\"\"\"Simple passthrough to SQLAlchemy connectable\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1424\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnectable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecution_options\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1425\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/cis545/lib/python3.7/site-packages/sqlalchemy/engine/base.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, statement, *multiparams, **params)\u001b[0m\n\u001b[1;32m   1278\u001b[0m                 \u001b[0m_EMPTY_EXECUTION_OPTS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1279\u001b[0;31m                 \u001b[0mfuture\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1280\u001b[0m             )\n",
      "\u001b[0;32m~/opt/anaconda3/envs/cis545/lib/python3.7/site-packages/sqlalchemy/engine/base.py\u001b[0m in \u001b[0;36m_exec_driver_sql\u001b[0;34m(self, statement, multiparams, params, execution_options, future)\u001b[0m\n\u001b[1;32m   1584\u001b[0m             \u001b[0mstatement\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1585\u001b[0;31m             \u001b[0mdistilled_parameters\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1586\u001b[0m         )\n",
      "\u001b[0;32m~/opt/anaconda3/envs/cis545/lib/python3.7/site-packages/sqlalchemy/engine/base.py\u001b[0m in \u001b[0;36m_execute_context\u001b[0;34m(self, dialect, constructor, statement, parameters, execution_options, *args, **kw)\u001b[0m\n\u001b[1;32m   1845\u001b[0m             self._handle_dbapi_exception(\n\u001b[0;32m-> 1846\u001b[0;31m                 \u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcursor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1847\u001b[0m             )\n",
      "\u001b[0;32m~/opt/anaconda3/envs/cis545/lib/python3.7/site-packages/sqlalchemy/engine/base.py\u001b[0m in \u001b[0;36m_handle_dbapi_exception\u001b[0;34m(self, e, statement, parameters, cursor, context)\u001b[0m\n\u001b[1;32m   2026\u001b[0m                 util.raise_(\n\u001b[0;32m-> 2027\u001b[0;31m                     \u001b[0msqlalchemy_exception\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwith_traceback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfrom_\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2028\u001b[0m                 )\n",
      "\u001b[0;32m~/opt/anaconda3/envs/cis545/lib/python3.7/site-packages/sqlalchemy/util/compat.py\u001b[0m in \u001b[0;36mraise_\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    206\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 207\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    208\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/cis545/lib/python3.7/site-packages/sqlalchemy/engine/base.py\u001b[0m in \u001b[0;36m_execute_context\u001b[0;34m(self, dialect, constructor, statement, parameters, execution_options, *args, **kw)\u001b[0m\n\u001b[1;32m   1802\u001b[0m                     self.dialect.do_execute(\n\u001b[0;32m-> 1803\u001b[0;31m                         \u001b[0mcursor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1804\u001b[0m                     )\n",
      "\u001b[0;32m~/opt/anaconda3/envs/cis545/lib/python3.7/site-packages/sqlalchemy/engine/default.py\u001b[0m in \u001b[0;36mdo_execute\u001b[0;34m(self, cursor, statement, parameters, context)\u001b[0m\n\u001b[1;32m    731\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdo_execute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcursor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 732\u001b[0;31m         \u001b[0mcursor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    733\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOperationalError\u001b[0m: (sqlite3.OperationalError) no such table: vaild_values_pollution\n[SQL: \nSELECT AVG(temperature) as temperature , AVG(pm25) as pm25, short_date\nFROM vaild_values_pollution\nGROUP BY short_date \n]\n(Background on this error at: https://sqlalche.me/e/14/e3q8)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mPandaSQLException\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/1l/w4y7yw0d3696kyv235sfd3hw0000gn/T/ipykernel_13825/2633883652.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mGROUP\u001b[0m \u001b[0mBY\u001b[0m \u001b[0mshort_date\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m '''\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mtemp_and_pm25\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpsql\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqldf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/envs/cis545/lib/python3.7/site-packages/pandasql/sqldf.py\u001b[0m in \u001b[0;36msqldf\u001b[0;34m(query, env, db_uri)\u001b[0m\n\u001b[1;32m    154\u001b[0m     \u001b[0;34m>>\u001b[0m\u001b[0;34m>\u001b[0m \u001b[0msqldf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"select avg(x) from df;\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m     \"\"\"\n\u001b[0;32m--> 156\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mPandaSQL\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdb_uri\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/envs/cis545/lib/python3.7/site-packages/pandasql/sqldf.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, query, env)\u001b[0m\n\u001b[1;32m     61\u001b[0m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_sql\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mDatabaseError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mPandaSQLException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mResourceClosedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m                 \u001b[0;31m# query returns nothing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mPandaSQLException\u001b[0m: (sqlite3.OperationalError) no such table: vaild_values_pollution\n[SQL: \nSELECT AVG(temperature) as temperature , AVG(pm25) as pm25, short_date\nFROM vaild_values_pollution\nGROUP BY short_date \n]\n(Background on this error at: https://sqlalche.me/e/14/e3q8)"
     ]
    }
   ],
   "source": [
    "query = '''\n",
    "SELECT AVG(temperature) as temperature , AVG(pm25) as pm25, short_date\n",
    "FROM vaild_values_pollution\n",
    "GROUP BY short_date \n",
    "'''\n",
    "temp_and_pm25 = psql.sqldf(query)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UCrCmMIwLMCW"
   },
   "source": [
    "Observations\n",
    "\n",
    "\n",
    "*   The winter month when the tempature are lower, there is a higher rate of pollution. The immediate relationship between the pollution and tempature is inverse relationship\n",
    "*   The is a gradual decrease in pollutions \n",
    "*   There is a gradual increase in highest and lowest tempature \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357
    },
    "id": "tsPrbX5GF7NK",
    "outputId": "604c069e-cc32-4a19-90d6-762e24c62ac4"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'temp_and_pm25' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/1l/w4y7yw0d3696kyv235sfd3hw0000gn/T/ipykernel_13825/2929482548.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mDate\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mtemp_and_pm25\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'short_date'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtemp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtemp_and_pm25\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'temperature'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mpm25\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtemp_and_pm25\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'pm25'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'temp_and_pm25' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "Date =  temp_and_pm25['short_date']\n",
    "temp = temp_and_pm25['temperature']\n",
    "pm25 = temp_and_pm25['pm25']\n",
    "\n",
    "plt.plot(Date, temp, label = \"temperature\" )\n",
    "plt.plot(Date, pm25, label = \"pollution\" )\n",
    "plt.legend()\n",
    "\n",
    "plt.title(\"Temp and pollution comparision plot\", fontsize = 20) # for title\n",
    "plt.xlabel(\"Date\", fontsize = 12) # label for x-axis\n",
    "plt.ylabel(\"Temp /pollution\", fontsize = 12) # label for y-axis\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SD8zp22LS3os"
   },
   "source": [
    "# 3 Creating Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C5OklkoiTkFA"
   },
   "source": [
    "#### **3.1.** Correlation of Feature Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PRHFTLGI-yNB"
   },
   "source": [
    "There will be two sets of each steps because the same process was ran acorss one dataset with population and one with out population information. Both datasets have about 250k records. The dataset without population information also had none deterministic values like 0.0 dropped from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 426
    },
    "id": "iLkDcGgRTjVH",
    "outputId": "19718585-0c66-40e2-d66d-ae9a59faaada"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'weather_with_pop' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/1l/w4y7yw0d3696kyv235sfd3hw0000gn/T/ipykernel_13825/2765550870.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mweather_with_pop_corr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweather_with_pop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheatmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweather_with_pop_corr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mannot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'weather_with_pop' is not defined"
     ]
    }
   ],
   "source": [
    "weather_with_pop_corr = weather_with_pop.corr()\n",
    "sns.heatmap(data = weather_with_pop_corr, annot=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mWO2JqCCrcqE"
   },
   "source": [
    "dew, pressure, no2, population, wind-gust, uvi, so2, wind-speed, pm25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "-WVzOZHXWReb"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'vaild_values_pollution' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/1l/w4y7yw0d3696kyv235sfd3hw0000gn/T/ipykernel_13825/3883202456.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mvaild_values_pollution\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvaild_values_pollution\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'mepaqi'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'vaild_values_pollution' is not defined"
     ]
    }
   ],
   "source": [
    "vaild_values_pollution = vaild_values_pollution.drop(columns = ['mepaqi'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 382
    },
    "id": "5qO7tZjA7TeX",
    "outputId": "f0feb400-ee71-4a03-ce1f-e895e062eb03"
   },
   "outputs": [],
   "source": [
    "weather_corr = vaild_values_pollution.corr()\n",
    "sns.heatmap(data = weather_corr, annot=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AEv_kUjQZOs_"
   },
   "source": [
    "#### **3.2** Select the key columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VUtz5Xsi75Ok"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rzlEU1wu8ACs"
   },
   "outputs": [],
   "source": [
    "new_weather_df = weather_with_pop[['dew', 'pressure', 'no2', 'Population', 'wind-gust', 'so2', 'wind-speed', 'pm25', 'pm10', 'temperature','City','Country','month', 'humidity', 'short_date', 'co']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kVBIwcFPGURA"
   },
   "outputs": [],
   "source": [
    "new_weather_df2 = vaild_values_pollution[['dew', 'pressure', 'no2', 'wind-gust', 'so2', 'pm25', 'pm10', 'temperature','City','Country','month', 'humidity', 'short_date','co']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IjNgNx9UEWX1"
   },
   "source": [
    "#### **3.2** Encode Categorical Variables using LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "abM1lZzgD86v"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "el = LabelEncoder()\n",
    "city_labels = el.fit_transform(new_weather_df['City'])\n",
    "country_labels = el.fit_transform(new_weather_df['Country'])\n",
    "short_date_labels = el.fit_transform(new_weather_df['short_date'])\n",
    "\n",
    "city_labels2 = el.fit_transform(new_weather_df2['City'])\n",
    "country_labels2 = el.fit_transform(new_weather_df2['Country'])\n",
    "short_date_labels2 = el.fit_transform(new_weather_df2['short_date'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "D3LZZXoLFXBK",
    "outputId": "398294f3-9a4b-48a2-b328-f625da032082"
   },
   "outputs": [],
   "source": [
    "new_weather_df['city_labels'] = city_labels\n",
    "new_weather_df['country_labels'] = country_labels\n",
    "new_weather_df['short_date_labels'] = short_date_labels\n",
    "\n",
    "\n",
    "new_weather_df2['city_labels'] = city_labels2\n",
    "new_weather_df2['country_labels'] = country_labels2\n",
    "new_weather_df2['short_date_labels'] = short_date_labels2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 439
    },
    "id": "qTsLVr2LaMPX",
    "outputId": "1b7392dd-5713-4e01-e503-c7ad64af17a5"
   },
   "outputs": [],
   "source": [
    "# updated correlation heatmap based on feature variables\n",
    "updated_weather_df_corr = new_weather_df.corr()\n",
    "\n",
    "#  heatmap for easier visualization\n",
    "sns.heatmap(data = updated_weather_df_corr, annot=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 377
    },
    "id": "JxPGWM4_7sdK",
    "outputId": "afaf92e9-ba3b-4e97-8a91-65d188f2e482"
   },
   "outputs": [],
   "source": [
    "updated_weather_df2_cor = new_weather_df2.corr()\n",
    "sns.heatmap(data = updated_weather_df2_cor, annot=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PT5rC1pbaYLz"
   },
   "source": [
    "#### **3.4** Split into Features and Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "umY1KyvTBmA7"
   },
   "outputs": [],
   "source": [
    "features = new_weather_df[['dew', 'pressure', 'no2', 'Population', 'wind-gust', 'so2', 'wind-speed', 'pm25', 'short_date_labels', 'country_labels', 'city_labels', 'pm10','co' ]]\n",
    "labels = new_weather_df['temperature']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gSyJCrT-cW0q",
    "outputId": "876c770c-dd3a-42b7-f16b-b889defd6594"
   },
   "outputs": [],
   "source": [
    "print(features.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5N0lwxGT77Ku"
   },
   "outputs": [],
   "source": [
    "features2 = new_weather_df2[['dew', 'pressure', 'no2', 'wind-gust', 'so2', 'pm25', 'pm10', 'temperature','month', 'humidity', 'country_labels', 'city_labels', 'short_date_labels','co']]\n",
    "labels2 = new_weather_df2['temperature']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i69DmPircbC5",
    "outputId": "21dba45a-f8f4-4822-e0bc-e68b0b56b964"
   },
   "outputs": [],
   "source": [
    "print(features2.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "59wH0wb-GZcH"
   },
   "source": [
    "Change all data type to int for using Naive Bayes classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ubE1d9JfGbz1"
   },
   "outputs": [],
   "source": [
    "features = features.astype('int64')\n",
    "labels = labels.astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gvV4Ou_wMvCT"
   },
   "outputs": [],
   "source": [
    "features2 = features2.astype('int64')\n",
    "labels2 = labels2.astype('int64')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RWkMIUvcaa8U"
   },
   "source": [
    "### **3.5** Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KadZp__0alqr"
   },
   "source": [
    "#### **3.5.1** Split Data into Train and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OvxPXCRxaqj2"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(features, labels, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split by years \n",
    "#Training 2019 \n",
    "#Validation 2020 \n",
    "#Testing 2021\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sjom-kvy8QF7"
   },
   "outputs": [],
   "source": [
    "x_train2, x_test2, y_train2, y_test2 = train_test_split(features2, labels2, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k4oCCBkca1wm"
   },
   "source": [
    "#### **3.5.2**  Naive Bayes classification "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SLeMcpG6a-gd",
    "outputId": "a63c7eeb-745c-41e9-d739-bf0dc731a00c"
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "\n",
    "# TODO model \n",
    "nb = GaussianNB()\n",
    "nb.fit(x_train, y_train)\n",
    "y_pred = nb.predict(x_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RsDrlPGw8VLN",
    "outputId": "a6f29c64-bac7-4395-830e-e718a1f082ef"
   },
   "outputs": [],
   "source": [
    "nb2 = GaussianNB()\n",
    "nb2.fit(x_train2, y_train2)\n",
    "y_pred2 = nb2.predict(x_test2)\n",
    "y_pred2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ep8tEHswbBjm",
    "outputId": "32c410da-bc9f-46d5-9d52-e0eca23f5de3"
   },
   "outputs": [],
   "source": [
    "comparison =  np.where(y_pred == y_test, True, False)\n",
    "naive_bayes_acc = sum(comparison== True)/ len(y_test)\n",
    "\n",
    "print(naive_bayes_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nILLCc2P8ZaG",
    "outputId": "cb119dfb-fbce-4faf-f6ff-97aa0310b578"
   },
   "outputs": [],
   "source": [
    "comparison2 =  np.where(y_pred2 == y_test2, True, False)\n",
    "naive_bayes_acc2 = sum(comparison2== True)/ len(y_test2)\n",
    "\n",
    "print(naive_bayes_acc2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1tqQ1yFOi1Ih"
   },
   "source": [
    "Plot the comparision "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S7HE0N-ErXbX"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "esFbe5UUbIvK"
   },
   "source": [
    "#### **3.5.3** Dimensionality Reduction with PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qGX0SqE2t0H6"
   },
   "outputs": [],
   "source": [
    "y_pred2\n",
    "prediction = pd.DataFrame(y_pred2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WmKRn8K1t0kB"
   },
   "outputs": [],
   "source": [
    "y_test2\n",
    "test = pd.DataFrame(y_test2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-19AaWfTuAWE"
   },
   "outputs": [],
   "source": [
    "test['month'] = x_test2['month']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kTg3R1tuxBcw"
   },
   "outputs": [],
   "source": [
    "test = test.reset_index()\n",
    "test = test.rename(columns={'temperature': 'actual'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4ExHUcqDwiU-"
   },
   "outputs": [],
   "source": [
    "test = pd.merge(test, prediction, left_index=True, right_index= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "id": "_YcRn_akyeok",
    "outputId": "61d74d81-ee9f-499e-eacc-49c3e39eece4"
   },
   "outputs": [],
   "source": [
    "test = test.rename(columns={0: 'prediction'})\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fUXnfOSwi0iF"
   },
   "outputs": [],
   "source": [
    "\n",
    "import plotly.express as px\n",
    "\n",
    "px.line(test, x = \"month\", y =\"actual\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 963
    },
    "id": "pfaWdp5DbVyg",
    "outputId": "bfd934a9-80e0-4088-eee9-7acb26bc056a"
   },
   "outputs": [],
   "source": [
    "# TO DO PCA\n",
    "# scaling\n",
    "# find num components to use\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaled_x_train = scaler.fit_transform(x_train)\n",
    "scaled_x_test = scaler.transform(x_test)\n",
    "\n",
    "pca = PCA(n_components = 12)\n",
    "pca_x_train = pca.fit_transform(scaled_x_train)\n",
    "\n",
    "\n",
    "print(pca_x_train.shape)\n",
    "\n",
    "print(pca.components_)\n",
    "# TO DO plot for explained variance\n",
    "pca.explained_variance_ratio_\n",
    "plt.plot(np.arange(0, 12), np.cumsum(pca.explained_variance_ratio_))\n",
    "plt.plot(np.arange(0, 12), [0.95]*12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "fv-896c3d737",
    "outputId": "6ad21dc4-717d-4234-fb68-4e5c7b3bae7e"
   },
   "outputs": [],
   "source": [
    "scaler2 = StandardScaler()\n",
    "scaled_x_train2 = scaler.fit_transform(x_train2)\n",
    "scaled_x_test2 = scaler.transform(x_test2)\n",
    "\n",
    "pca = PCA(n_components = 14)\n",
    "pca_x_train2 = pca.fit_transform(scaled_x_train2)\n",
    "\n",
    "\n",
    "print(pca_x_train.shape)\n",
    "\n",
    "print(pca.components_)\n",
    "# TO DO plot for explained variance\n",
    "pca.explained_variance_ratio_\n",
    "plt.plot(np.arange(0, 14), np.cumsum(pca.explained_variance_ratio_))\n",
    "plt.plot(np.arange(0, 14), [0.95]*14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ukSkoVYMbZcN",
    "outputId": "24d03348-2efd-4064-9a9a-cdb88be6e80b"
   },
   "outputs": [],
   "source": [
    "explained_variance = pca.explained_variance_ratio_\n",
    "print(explained_variance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WoYJEULgbc2J"
   },
   "outputs": [],
   "source": [
    "pca = PCA(n_components=11 ) # TODO update this number\n",
    "x_train_pca = pca.fit_transform(scaled_x_train)\n",
    "x_test_pca  = pca.transform(scaled_x_test)\n",
    "x_train = x_train_pca\n",
    "x_test = x_test_pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mEl4vRO3fQIq"
   },
   "outputs": [],
   "source": [
    "pca = PCA(n_components=11 ) # TODO update this number\n",
    "x_train_pca2 = pca.fit_transform(scaled_x_train2)\n",
    "x_test_pca2  = pca.transform(scaled_x_test2)\n",
    "x_train2 = x_train_pca2\n",
    "x_test2 = x_test_pca2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c_cWw3T1uJ2-"
   },
   "source": [
    "Reducing the PCA to 2 and plotting the result to see the outcome "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 351
    },
    "id": "ov5Yq4lobh9c",
    "outputId": "bf863127-cbe6-4c93-88c7-fefcf26beae8"
   },
   "outputs": [],
   "source": [
    "# visualize 2 components of PCA\n",
    "pca_plot = PCA(n_components=2)\n",
    "comp = pca_plot.fit_transform(x_train_pca)\n",
    "data = np.transpose(np.array(comp))\n",
    "plt.scatter(data[0][0:5000], data[1][0:5000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 351
    },
    "id": "aqy96ndrfqvA",
    "outputId": "f43b2675-4236-4b00-c4ce-e21299f7acbd"
   },
   "outputs": [],
   "source": [
    "# visualize 2 components of PCA\n",
    "pca_plot = PCA(n_components=2)\n",
    "comp = pca_plot.fit_transform(x_train_pca2)\n",
    "data = np.transpose(np.array(comp))\n",
    "plt.scatter(data[0][0:5000], data[1][0:5000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gp1KXhaVbllU"
   },
   "source": [
    "#### 3.5.4 Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "meHu5-KZJ5Nw"
   },
   "outputs": [],
   "source": [
    "def print_best_params(results):\n",
    "    print('best_params: {}\\n'.format(results.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2bRzsmiuJ8O3",
    "outputId": "cdd02cd6-1f96-4fdd-af3e-ea61c7a2b5db"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "#from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "\n",
    "\n",
    "tree = RandomForestClassifier()\n",
    "\n",
    "parameters = {'max_depth':[1, 10], 'n_estimators': [1,10]}\n",
    "rf_cv = GridSearchCV(tree,parameters).fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use this \n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "X, y = make_regression(n_features=4, n_informative=2,\n",
    "                       random_state=0, shuffle=False)\n",
    "\n",
    "regr = RandomForestRegressor(max_depth=2, random_state=0, n_jobs =2, verbose =1)\n",
    "regr.fit(X, y)\n",
    "\n",
    "print(regr.predict([[0, 0, 0, 0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TDqPfxlZf3g9",
    "outputId": "d5ceefb1-8fdd-4904-a4bd-23351a313c75"
   },
   "outputs": [],
   "source": [
    "#from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "tree2 = RandomForestClassifier()\n",
    "\n",
    "parameters2 = {'max_depth':[1, 10], 'n_estimators': [1,10]}\n",
    "rf_cv2 = GridSearchCV(tree2,parameters2).fit(x_train2, y_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ba_NDc0yKBjq",
    "outputId": "6f016b14-33c2-4a25-84f4-d26a3c241761"
   },
   "outputs": [],
   "source": [
    "print_best_params(rf_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KLeJG7qXKG4R",
    "outputId": "7252a88a-6f52-4cd2-e3af-1a2db701a817"
   },
   "outputs": [],
   "source": [
    "# TODO\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "rf_cv.fit(x_train, y_train)\n",
    "prediction = rf_cv.predict(x_test)\n",
    "test_accuracy = accuracy_score(prediction, y_test)\n",
    "print(test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3eVStraZhVYZ",
    "outputId": "860b72c4-c2a8-41a0-c7f4-eec66bc14ad8"
   },
   "outputs": [],
   "source": [
    "rf_cv2.fit(x_train2, y_train2)\n",
    "prediction2 = rf_cv2.predict(x_test2)\n",
    "test_accuracy2 = accuracy_score(prediction2, y_test2)\n",
    "print(test_accuracy2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZN0-YG2LH1e0"
   },
   "source": [
    "## 3.6 Modeling with Timeseries approach (Arima and Sarima "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NMHd9puoJsrt"
   },
   "source": [
    "### 3.6.0 Arima time series model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install pandas\n",
    "!pip install plotly-express\n",
    "!pip install statsmodels\n",
    "!pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "L0_qJPTNJAh8",
    "outputId": "1256e91c-2a98-442b-b54c-7452eba49834"
   },
   "outputs": [],
   "source": [
    " \n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import statsmodels as sm \n",
    "from sklearn.metrics import r2_score\n",
    "from tqdm import tqdm\n",
    "import plotly.express as px\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# model imports\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "import statsmodels.api as sm1\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import itertools\n",
    "import math\n",
    "from sklearn.decomposition import PCA\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ahde5Y6viwdF"
   },
   "source": [
    "### 3.6.1 Scaling Data By Standard Scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BEUIGutl8PGs"
   },
   "outputs": [],
   "source": [
    "def get_country_df(country):\n",
    "    df = pd.read_csv('../Data/global_average_yearly_temp_with_features_clean.csv')\n",
    "    df = df[df[\"iso_code\"] == country]\n",
    "    df[\"Year_idx\"] = pd.to_datetime(df.year, format=\"%Y\")\n",
    "    df = df.set_index(\"Year_idx\")\n",
    "    df.index = df.index.to_period(\"Y\")\n",
    "    return df\n",
    "\n",
    "def get_test_train_valid(country, train_split = '1950', validation_split = '1980'):\n",
    "    country_df = get_country_df(country)\n",
    "    \n",
    "    train = country_df.loc[:train_split]\n",
    "    valid = country_df.loc[train_split: validation_split]\n",
    "    test  = country_df.loc[validation_split:]\n",
    "    \n",
    "    return train, test, valid\n",
    "\n",
    "def scale(train_x, valid_x, test_x):\n",
    "    scaler = StandardScaler()\n",
    "    model_x = pd.concat([train_x, valid_x])\n",
    "\n",
    "    scaler.fit(model_x)\n",
    "    model_x = scaler.transform(model_x)\n",
    "    train_x = scaler.transform(train_x)\n",
    "    valid_x = scaler.transform(valid_x)\n",
    "    test_x  = scaler.transform(test_x)\n",
    "    return train_x, valid_x, test_x, model_x\n",
    "\n",
    "def pca_fitter(train_x, threshold = .99):\n",
    "    n_features = train_x.shape[1]\n",
    "    \n",
    "    for n in range(1, n_features + 1):\n",
    "        pca_model = PCA(n)\n",
    "        pca_model.fit(train_x)\n",
    "        \n",
    "        if sum(pca_model.explained_variance_ratio_) >= threshold:\n",
    "            break\n",
    "    return pca_model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hb5nRzcFsA1S"
   },
   "source": [
    "### 3.6.2 Hypertuning Model Parameters With Training and Validation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iQZpH4fGrUdJ"
   },
   "outputs": [],
   "source": [
    "def eval_arima_excog_walk_forward_validation_model(train_x, train_y, test_x, test_y, arima_order):\n",
    "    # DO NOT USE THIS \n",
    "\n",
    "    history = [x for x in train_y]\n",
    "    predictions = []\n",
    "    \n",
    "    for i in range(len(test_x)):\n",
    "        model = ARIMA(history, exog = train_x, order = arima_order)\n",
    "        model_fit = model.fit()\n",
    "        \n",
    "        y_hat = model_fit.forecast(exog = test_x.iloc[[i]])\n",
    "        predictions.append(y_hat[0])\n",
    "        \n",
    "        train_x = pd.concat([train_x, test_x.iloc[[i]]], axis = 0)\n",
    "        history.append(test_y[i])\n",
    "\n",
    "    rmse = math.sqrt(mean_squared_error(test_y, predictions))\n",
    "    return model_fit, rmse, predictions\n",
    "\n",
    "def eval_arima_excog(train_x, train_y, test_x, test_y, arima_order, trend = 'c'):\n",
    "    # DO NOT USE THIS \n",
    "    model = ARIMA(train_y, exog = train_x, order = arima_order, trend = trend)\n",
    "    model_fit = model.fit()\n",
    "    predictions = model_fit.forecast(len(test_x), exog = test_x)\n",
    "    rmse = math.sqrt(mean_squared_error(test_y, predictions))\n",
    "    return model_fit, rmse, predictions\n",
    "\n",
    "def eval_sarimax_excog(train_x, train_y, test_x, test_y, arima_order):\n",
    "    # USE THIS\n",
    "    model = sm1.tsa.statespace.SARIMAX(train_y, exog = train_x, order = arima_order, \\\n",
    "                                       time_varying_regression = True, mle_regression = False, measurement_error = True)\n",
    "    model_fit = model.fit(disp = 0)\n",
    "    predictions = model_fit.forecast(len(test_x), exog = test_x)\n",
    "    rmse = math.sqrt(mean_squared_error(test_y, predictions))\n",
    "    predictions.index = test_y.index\n",
    "    return model_fit, rmse, predictions\n",
    "\n",
    "def eval_excog_models(train_x, train_y, test_x, test_y, p_values, d_values, q_values, f):\n",
    "    arima_orders = itertools.product(*[p_values, d_values, q_values])\n",
    "    arima_orders = list(arima_orders)\n",
    "    best_order, best_score = None, float(\"inf\") \n",
    "    \n",
    "    count = 0\n",
    "    for arima_order in tqdm(arima_orders):\n",
    "        try:\n",
    "            _, rmse, _ = f(train_x, train_y, test_x, test_y, arima_order)\n",
    "            \n",
    "            if rmse < best_score:\n",
    "                best_score, best_order = rmse, arima_order\n",
    "                print(f\"ARIMA RMSE = {best_score}\")\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            pass\n",
    "        count += 1\n",
    "    print('DONE')\n",
    "    return best_order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vmylFXRUrd9Y"
   },
   "outputs": [],
   "source": [
    "def ml(country, p_values = [0, 1, 2, 3], d_values = range(0, 3), q_values = range(0, 3)):\n",
    "    train, test, valid = get_test_train_valid(country)\n",
    "\n",
    "    train_x, train_y = train[train.columns[2:-2]], train[\"AvgYearlyTemp\"]\n",
    "    test_x, test_y = test[test.columns[2:-2]], test[\"AvgYearlyTemp\"]\n",
    "    valid_x, valid_y = valid[valid.columns[2:-2]], valid[\"AvgYearlyTemp\"]\n",
    "\n",
    "    train_x, valid_x, test_x, model_x = scale(train_x, valid_x, test_x)\n",
    "\n",
    "    pca_model = pca_fitter(train_x)\n",
    "    train_x = pca_model.transform(train_x)\n",
    "    valid_x = pca_model.transform(valid_x) \n",
    "    test_x  = pca_model.transform(test_x)\n",
    "    model_x = pca_model.transform(model_x)\n",
    "    \n",
    "    model_y = pd.concat([train_y, valid_y])\n",
    "\n",
    "    best = eval_excog_models(train_x, train_y, valid_x, valid_y, p_values, d_values, q_values, eval_sarimax_excog)\n",
    "\n",
    "    model_fit, rmse, predictions = eval_sarimax_excog(model_x, model_y, test_x, test_y, best)\n",
    "    \n",
    "    return best, test_y, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RmjdXyAxsNIz"
   },
   "outputs": [],
   "source": [
    "def plot(df, country, layout, line1 = 'AvgYearlyTemp', line2 = 'Predictions', x = 'year', error = 'AvgTempUncertainty'):\n",
    "    from plotly.subplots import make_subplots\n",
    "    import plotly.graph_objects as go\n",
    "\n",
    "\n",
    "    fig = go.Figure(layout = layout)\n",
    "    trace_1 = go.Line(name = f\"Actual {country} Avg Yearly Temp\", \n",
    "                     x = test[x],\n",
    "                     y = test[line1],\n",
    "                     error_y = dict(type='data', array = test[error]))\n",
    "\n",
    "\n",
    "    trace_2 = go.Line(name = f\"Predictions of {country} Avg Yearly Temp\", \n",
    "                     x = test[x],\n",
    "                     y = test[line2])\n",
    "\n",
    "    fig.add_trace(trace_1)\n",
    "    fig.add_trace(trace_2)\n",
    "    \n",
    "    return fig"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNer6090hZRnqvdJ0k1Tm6l",
   "collapsed_sections": [],
   "include_colab_link": true,
   "mount_file_id": "1XKO4eEKuGD8EvNZtLa0fggHZmpLTRy-H",
   "name": "Seasonal_weather_data _analysis.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
